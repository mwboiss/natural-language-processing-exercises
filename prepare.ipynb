{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "721f8f8f-66ad-47a4-8ce3-a760b4a6fb5d",
   "metadata": {},
   "source": [
    "# Data Preperation Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a535fcdb-8783-46ff-918f-8c160ebec9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import acquire\n",
    "import prepare\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa10cf7-0a0e-4ab8-988a-5ffb3e720a40",
   "metadata": {},
   "source": [
    "## In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c99751-2a8a-4917-9e05-b46e0db8fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_blog_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05229e07-dcaa-46b7-b6b0-418e6b2ba82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>published</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Learn to Code: Python Workshop on 4/23</td>\n",
       "      <td>Mar 31, 2022</td>\n",
       "      <td>According to LinkedIn, the “#1 Most Promising ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coming Soon: Cloud Administration</td>\n",
       "      <td>Mar 17, 2022</td>\n",
       "      <td>We’re launching a new program out of San Anton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 Books Every Woman In Tech Should Read</td>\n",
       "      <td>Mar 8, 2022</td>\n",
       "      <td>On this International Women’s Day 2022 we want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Codeup Start Dates for March 2022</td>\n",
       "      <td>Jan 26, 2022</td>\n",
       "      <td>As we approach the end of January we wanted to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VET TEC Funding Now Available For Dallas Veterans</td>\n",
       "      <td>Jan 7, 2022</td>\n",
       "      <td>We are so happy to announce that VET TEC benef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     published  \\\n",
       "0             Learn to Code: Python Workshop on 4/23  Mar 31, 2022   \n",
       "1                  Coming Soon: Cloud Administration  Mar 17, 2022   \n",
       "2            5 Books Every Woman In Tech Should Read   Mar 8, 2022   \n",
       "3                  Codeup Start Dates for March 2022  Jan 26, 2022   \n",
       "4  VET TEC Funding Now Available For Dallas Veterans   Jan 7, 2022   \n",
       "\n",
       "                                             content  \n",
       "0  According to LinkedIn, the “#1 Most Promising ...  \n",
       "1  We’re launching a new program out of San Anton...  \n",
       "2  On this International Women’s Day 2022 we want...  \n",
       "3  As we approach the end of January we wanted to...  \n",
       "4  We are so happy to announce that VET TEC benef...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671cf6fc-9758-4be0-9013-66a6bd95a4ae",
   "metadata": {},
   "source": [
    "## 1) Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f4d06d-6179-472e-9c8d-9801627180fd",
   "metadata": {},
   "source": [
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb39d782-02c8-4c53-8a90-69990c68071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(instr):\n",
    "    '''\n",
    "    Clean our data by making everything lowercase, normalize unicode characters, and removing unwanted characters\n",
    "    '''\n",
    "    # Lower case\n",
    "    instr = instr.lower()\n",
    "    # Normalize\n",
    "    instr = unicodedata.normalize('NFKD' , instr).encode('ascii','ignore').decode('utf-8', 'ignore')\n",
    "    # remove unwanted characters\n",
    "    instr = re.sub(f\"[^a-z0-9'\\s]\", '', instr)\n",
    "    # Return the cleaned string\n",
    "    return instr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6311683b-2096-4718-9d99-130307d541ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to LinkedIn, the “#1 Most Promising Job” is data science! But we here at Codeup understand changing careers can be a daunting idea. That’s where our free Learn to Code workshops come in!\\xa0\\nOn Saturday 4/23 we will be teaching a free Learn to Code workshop on the programming language Python which is one of the major building blocks of Data Science!\\nWhat is data science? What is Python? \\nIf you’re curious, join for free to learn the basics of Python from our very own instructors and get an introduction to the field of Data Science. This is all done from the comfort of home.\\nSave your seat quickly – our Python workshops are always in high demand! \\nWhat you need:\\n1. Laptop (does not matter what kind). You need to be able to access WiFi and run an internet browser.\\n2. To RSVP!\\nYou can register for the event below!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.content[0]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a40cb43-e15f-4a8d-8e4b-c944e0768b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'according to linkedin the 1 most promising job is data science but we here at codeup understand changing careers can be a daunting idea thats where our free learn to code workshops come in \\non saturday 423 we will be teaching a free learn to code workshop on the programming language python which is one of the major building blocks of data science\\nwhat is data science what is python \\nif youre curious join for free to learn the basics of python from our very own instructors and get an introduction to the field of data science this is all done from the comfort of home\\nsave your seat quickly  our python workshops are always in high demand \\nwhat you need\\n1 laptop does not matter what kind you need to be able to access wifi and run an internet browser\\n2 to rsvp\\nyou can register for the event below'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cleaned = basic_clean(test)\n",
    "test_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee0cd2e-5225-4429-8734-2d79713d0c79",
   "metadata": {},
   "source": [
    "## 2) Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a20f4a-9cad-436e-9b1c-8f29e5c12291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(instr):\n",
    "    '''\n",
    "    Tokenize the target string. We breakup words and puctuation into descrete units\n",
    "    '''\n",
    "    \n",
    "    tokenizer = ToktokTokenizer()\n",
    "    \n",
    "    instr = tokenizer.tokenize(instr, return_str = True)\n",
    "    \n",
    "    return instr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ab0854-89e7-4da3-b70f-44c8109f1cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'according to linkedin the 1 most promising job is data science but we here at codeup understand changing careers can be a daunting idea thats where our free learn to code workshops come in \\non saturday 423 we will be teaching a free learn to code workshop on the programming language python which is one of the major building blocks of data science\\nwhat is data science what is python \\nif youre curious join for free to learn the basics of python from our very own instructors and get an introduction to the field of data science this is all done from the comfort of home\\nsave your seat quickly our python workshops are always in high demand \\nwhat you need\\n1 laptop does not matter what kind you need to be able to access wifi and run an internet browser\\n2 to rsvp\\nyou can register for the event below'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tokenized = tokenize(test_cleaned)\n",
    "test_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff7bde0-fa54-48c8-a66e-cba3c1fddad6",
   "metadata": {},
   "source": [
    "## 3) Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fba2def-2171-4253-9a6a-639c70958463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(instr):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    stems = [ps.stem(word) for word in instr.split()]\n",
    "    \n",
    "    instr = ' '.join(stems)\n",
    "    \n",
    "    return instr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6211ac7d-2dc4-4043-a8a5-b06b81d9c1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accord to linkedin the 1 most promis job is data scienc but we here at codeup understand chang career can be a daunt idea that where our free learn to code workshop come in on saturday 423 we will be teach a free learn to code workshop on the program languag python which is one of the major build block of data scienc what is data scienc what is python if your curiou join for free to learn the basic of python from our veri own instructor and get an introduct to the field of data scienc thi is all done from the comfort of home save your seat quickli our python workshop are alway in high demand what you need 1 laptop doe not matter what kind you need to be abl to access wifi and run an internet browser 2 to rsvp you can regist for the event below'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stem = stem(test_tokenized)\n",
    "test_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1165f41b-313e-45f0-a8df-e5cf6b50e05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to        8\n",
       "the       7\n",
       "of        5\n",
       "is        5\n",
       "scienc    4\n",
       "python    4\n",
       "what      4\n",
       "data      4\n",
       "free      3\n",
       "you       3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(test_stem.split()).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507cca75-e97e-4eaf-a490-b3b50f6a6dbc",
   "metadata": {},
   "source": [
    "## 4) Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5706692-b8e8-46a0-81f3-d479b174c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(instr):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    lemmas = [wnl.lemmatize(word) for word in instr.split()]\n",
    "    \n",
    "    instr = ' '.join(lemmas)\n",
    "    \n",
    "    return instr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b990e7bc-732e-495a-b39a-f7761c00ecbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'according to linkedin the 1 most promising job is data science but we here at codeup understand changing career can be a daunting idea thats where our free learn to code workshop come in on saturday 423 we will be teaching a free learn to code workshop on the programming language python which is one of the major building block of data science what is data science what is python if youre curious join for free to learn the basic of python from our very own instructor and get an introduction to the field of data science this is all done from the comfort of home save your seat quickly our python workshop are always in high demand what you need 1 laptop doe not matter what kind you need to be able to access wifi and run an internet browser 2 to rsvp you can register for the event below'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lemma = lemmatize(test_tokenized)\n",
    "test_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b7b2346-a3f4-41e4-8574-74d59a935b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to         8\n",
       "the        7\n",
       "of         5\n",
       "is         5\n",
       "what       4\n",
       "python     4\n",
       "data       4\n",
       "science    4\n",
       "be         3\n",
       "you        3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(test_lemma.split()).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99317e6-e98d-4580-ae37-5719e431116d",
   "metadata": {},
   "source": [
    "## 5) Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "- This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7f12437-652c-4907-96be-48003d36a858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(instr, extra_words = [], exclude_words= []):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    if exclude_words: \n",
    "        for word in exclude_words:\n",
    "            stopword_list.remove(word)\n",
    "    \n",
    "    if extra_words:\n",
    "        for word in extra_words:\n",
    "            stopword_list.append(word)\n",
    "    \n",
    "    words = instr.split()\n",
    "    \n",
    "    filtered_words = [w for w in words if w not in stopword_list]\n",
    "    \n",
    "    words_removed = ' '.join(filtered_words)\n",
    "    \n",
    "    return words_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e61a5316-158f-43d8-bd35-b7b8beae5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_words = []\n",
    "exclude_words = ['to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "817cdd8d-c8ab-4667-98c4-3217b7d593bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to          8\n",
       "python      4\n",
       "data        4\n",
       "science     4\n",
       "workshop    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(remove_stopwords(test_lemma, exclude_words= exclude_words).split()).value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f69aa4-8d85-4dba-a6f6-f82470d91096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c89c06e2-ce24-4e74-81a5-66e968ff302c",
   "metadata": {},
   "source": [
    "## 6) Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4359c68-b6b1-4975-9195-0ed18b5a2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = acquire.get_news_articles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2787e1-419d-4a7a-a708-b061c7a9962d",
   "metadata": {},
   "source": [
    "## 7) Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8ec658b-0958-4811-b51a-76760d93a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df = acquire.get_blog_articles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92deaa8-875c-4c6f-9249-209d4cd2f07e",
   "metadata": {},
   "source": [
    "## 8) For each dataframe, produce the following columns:\n",
    "\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b550dc5f-2f98-4fec-80f4-ff3e626e698b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>author</th>\n",
       "      <th>published</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Rupee closes at all-time low of 77.50 against ...</td>\n",
       "      <td>The Indian rupee weakened further on Monday to...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>2022-05-09T15:27:43.000Z</td>\n",
       "      <td>0 indian rupee weakened monday 1 microsoft sai...</td>\n",
       "      <td>0 0 indian rupe weaken monday 1 microsoft sai....</td>\n",
       "      <td>0 0 indian rupee weakened monday 1 microsoft s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Microsoft to help cover US employees' travel c...</td>\n",
       "      <td>Microsoft has said that it will cover travel c...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>2022-05-10T03:42:26.000Z</td>\n",
       "      <td>0 indian rupee weakened monday 1 microsoft sai...</td>\n",
       "      <td>0 0 indian rupe weaken monday 1 microsoft sai....</td>\n",
       "      <td>0 0 indian rupee weakened monday 1 microsoft s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>When are you coming to deliver 1st Tesla? Payt...</td>\n",
       "      <td>Paytm CEO Vijay Shekhar Sharma took to Twitter...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>2022-05-10T05:08:13.000Z</td>\n",
       "      <td>0 indian rupee weakened monday 1 microsoft sai...</td>\n",
       "      <td>0 0 indian rupe weaken monday 1 microsoft sai....</td>\n",
       "      <td>0 0 indian rupee weakened monday 1 microsoft s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Layout of 'world's first Bitcoin City' in El S...</td>\n",
       "      <td>El Salvador's President Nayib Bukele has share...</td>\n",
       "      <td>Hiral Goyal</td>\n",
       "      <td>2022-05-10T13:24:11.000Z</td>\n",
       "      <td>0 indian rupee weakened monday 1 microsoft sai...</td>\n",
       "      <td>0 0 indian rupe weaken monday 1 microsoft sai....</td>\n",
       "      <td>0 0 indian rupee weakened monday 1 microsoft s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>After Musk's Taj Mahal tweet, his mother says ...</td>\n",
       "      <td>After Elon Musk tweeted he visited Taj Mahal i...</td>\n",
       "      <td>Apaar Sharma</td>\n",
       "      <td>2022-05-10T04:18:35.000Z</td>\n",
       "      <td>0 indian rupee weakened monday 1 microsoft sai...</td>\n",
       "      <td>0 0 indian rupe weaken monday 1 microsoft sai....</td>\n",
       "      <td>0 0 indian rupee weakened monday 1 microsoft s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                              title  \\\n",
       "0  business  Rupee closes at all-time low of 77.50 against ...   \n",
       "1  business  Microsoft to help cover US employees' travel c...   \n",
       "2  business  When are you coming to deliver 1st Tesla? Payt...   \n",
       "3  business  Layout of 'world's first Bitcoin City' in El S...   \n",
       "4  business  After Musk's Taj Mahal tweet, his mother says ...   \n",
       "\n",
       "                                            original          author  \\\n",
       "0  The Indian rupee weakened further on Monday to...  Pragya Swastik   \n",
       "1  Microsoft has said that it will cover travel c...  Ridham Gambhir   \n",
       "2  Paytm CEO Vijay Shekhar Sharma took to Twitter...  Ridham Gambhir   \n",
       "3  El Salvador's President Nayib Bukele has share...     Hiral Goyal   \n",
       "4  After Elon Musk tweeted he visited Taj Mahal i...    Apaar Sharma   \n",
       "\n",
       "                  published  \\\n",
       "0  2022-05-09T15:27:43.000Z   \n",
       "1  2022-05-10T03:42:26.000Z   \n",
       "2  2022-05-10T05:08:13.000Z   \n",
       "3  2022-05-10T13:24:11.000Z   \n",
       "4  2022-05-10T04:18:35.000Z   \n",
       "\n",
       "                                               clean  \\\n",
       "0  0 indian rupee weakened monday 1 microsoft sai...   \n",
       "1  0 indian rupee weakened monday 1 microsoft sai...   \n",
       "2  0 indian rupee weakened monday 1 microsoft sai...   \n",
       "3  0 indian rupee weakened monday 1 microsoft sai...   \n",
       "4  0 indian rupee weakened monday 1 microsoft sai...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  0 0 indian rupe weaken monday 1 microsoft sai....   \n",
       "1  0 0 indian rupe weaken monday 1 microsoft sai....   \n",
       "2  0 0 indian rupe weaken monday 1 microsoft sai....   \n",
       "3  0 0 indian rupe weaken monday 1 microsoft sai....   \n",
       "4  0 0 indian rupe weaken monday 1 microsoft sai....   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  0 0 indian rupee weakened monday 1 microsoft s...  \n",
       "1  0 0 indian rupee weakened monday 1 microsoft s...  \n",
       "2  0 0 indian rupee weakened monday 1 microsoft s...  \n",
       "3  0 0 indian rupee weakened monday 1 microsoft s...  \n",
       "4  0 0 indian rupee weakened monday 1 microsoft s...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = news_df.rename(columns={'content':'original'})\n",
    "news_df['clean'] = prepare.remove_stopwords(prepare.tokenize(prepare.basic_clean(str(news_df.original))))\n",
    "news_df['stemmed'] = prepare.stem(str(news_df.clean))\n",
    "news_df['lemmatized'] = prepare.lemmatize(str(news_df.clean))\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9277a36d-5c68-4deb-8fb3-aee03483f514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>published</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Learn to Code: Python Workshop on 4/23</td>\n",
       "      <td>Mar 31, 2022</td>\n",
       "      <td>According to LinkedIn, the “#1 Most Promising ...</td>\n",
       "      <td>0 according linkedin 1 promising 1 launching n...</td>\n",
       "      <td>0 0 accord linkedin 1 promis 1 launch n... 1 0...</td>\n",
       "      <td>0 0 according linkedin 1 promising 1 launching...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coming Soon: Cloud Administration</td>\n",
       "      <td>Mar 17, 2022</td>\n",
       "      <td>We’re launching a new program out of San Anton...</td>\n",
       "      <td>0 according linkedin 1 promising 1 launching n...</td>\n",
       "      <td>0 0 accord linkedin 1 promis 1 launch n... 1 0...</td>\n",
       "      <td>0 0 according linkedin 1 promising 1 launching...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 Books Every Woman In Tech Should Read</td>\n",
       "      <td>Mar 8, 2022</td>\n",
       "      <td>On this International Women’s Day 2022 we want...</td>\n",
       "      <td>0 according linkedin 1 promising 1 launching n...</td>\n",
       "      <td>0 0 accord linkedin 1 promis 1 launch n... 1 0...</td>\n",
       "      <td>0 0 according linkedin 1 promising 1 launching...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Codeup Start Dates for March 2022</td>\n",
       "      <td>Jan 26, 2022</td>\n",
       "      <td>As we approach the end of January we wanted to...</td>\n",
       "      <td>0 according linkedin 1 promising 1 launching n...</td>\n",
       "      <td>0 0 accord linkedin 1 promis 1 launch n... 1 0...</td>\n",
       "      <td>0 0 according linkedin 1 promising 1 launching...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VET TEC Funding Now Available For Dallas Veterans</td>\n",
       "      <td>Jan 7, 2022</td>\n",
       "      <td>We are so happy to announce that VET TEC benef...</td>\n",
       "      <td>0 according linkedin 1 promising 1 launching n...</td>\n",
       "      <td>0 0 accord linkedin 1 promis 1 launch n... 1 0...</td>\n",
       "      <td>0 0 according linkedin 1 promising 1 launching...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     published  \\\n",
       "0             Learn to Code: Python Workshop on 4/23  Mar 31, 2022   \n",
       "1                  Coming Soon: Cloud Administration  Mar 17, 2022   \n",
       "2            5 Books Every Woman In Tech Should Read   Mar 8, 2022   \n",
       "3                  Codeup Start Dates for March 2022  Jan 26, 2022   \n",
       "4  VET TEC Funding Now Available For Dallas Veterans   Jan 7, 2022   \n",
       "\n",
       "                                            original  \\\n",
       "0  According to LinkedIn, the “#1 Most Promising ...   \n",
       "1  We’re launching a new program out of San Anton...   \n",
       "2  On this International Women’s Day 2022 we want...   \n",
       "3  As we approach the end of January we wanted to...   \n",
       "4  We are so happy to announce that VET TEC benef...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  0 according linkedin 1 promising 1 launching n...   \n",
       "1  0 according linkedin 1 promising 1 launching n...   \n",
       "2  0 according linkedin 1 promising 1 launching n...   \n",
       "3  0 according linkedin 1 promising 1 launching n...   \n",
       "4  0 according linkedin 1 promising 1 launching n...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  0 0 accord linkedin 1 promis 1 launch n... 1 0...   \n",
       "1  0 0 accord linkedin 1 promis 1 launch n... 1 0...   \n",
       "2  0 0 accord linkedin 1 promis 1 launch n... 1 0...   \n",
       "3  0 0 accord linkedin 1 promis 1 launch n... 1 0...   \n",
       "4  0 0 accord linkedin 1 promis 1 launch n... 1 0...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  0 0 according linkedin 1 promising 1 launching...  \n",
       "1  0 0 according linkedin 1 promising 1 launching...  \n",
       "2  0 0 according linkedin 1 promising 1 launching...  \n",
       "3  0 0 according linkedin 1 promising 1 launching...  \n",
       "4  0 0 according linkedin 1 promising 1 launching...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df = codeup_df.rename(columns={'content':'original'})\n",
    "codeup_df['clean'] = prepare.remove_stopwords(prepare.tokenize(prepare.basic_clean(str(codeup_df.original))))\n",
    "codeup_df['stemmed'] = prepare.stem(str(codeup_df.clean))\n",
    "codeup_df['lemmatized'] = prepare.lemmatize(str(codeup_df.clean))\n",
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cba7622-6281-4560-91ea-367fa9d4239b",
   "metadata": {},
   "source": [
    "## 9) Ask yourself:\n",
    "\n",
    "- If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a324c80-c8f0-4d94-9871-162677327f03",
   "metadata": {},
   "source": [
    "- 493 KB I would probably use lemmatized as it is a small enough data set and though lemmatized is more computationally intensive it is more detailed in its approuch using words and not just cutting off the end like stemming. \n",
    "- 25 MB  I would still probably use lemmatized for the same reason above.\n",
    "- 200 TB I would probably switch to stemming here as efficiency would be important here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b486d36a-3712-4de6-8399-7fab94f784dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "848"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6e803ed-fc1a-4d4e-8a19-1d39ab710e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6528"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320319ed-ba70-4c74-b6c5-70a22f639daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
